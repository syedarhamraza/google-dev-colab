{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedarhamraza/google-dev-colab/blob/main/LLM_as_a_Judge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Evaluate RAG with Gemini using LLM as a JUDGE\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/irum-zahra-awan/geneai/blob/main/LLM_as_a_Judge.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/irum-zahra-awan/geneai/blob/main/LLM_as_a_Judge.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>    "
      ],
      "metadata": {
        "id": "9eF3GT_XRPeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Author |\n",
        "| --- |\n",
        "| [Irum Zahra](https://github.com/irum-zahra-awan/) |"
      ],
      "metadata": {
        "id": "rB9hq6aXRhuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview: RAG EVALUATION**\n",
        "Evaluating the quality of Large Language Model (LLM) outputs, especially within Retrieval-Augmented Generation (RAG) systems, can be challenging, time-consuming, and subjective.\n",
        "\n",
        "Evaluating RAG systems is crucial for ensuring they deliver **accurate**, **relevant**, and **grounded** responses. While traditional metrics have their place, the rise of Large Language Models (LLMs) as \"judges\" has revolutionized RAG evaluation, offering a more nuanced and scalable approach. And with the robust capabilities of Google's Gemini models, implementing this advanced evaluation is more accessible than ever.\n",
        "\n",
        "This hands-on workshop introduces the **\"LLM as a Judge\"** paradigm, a powerful and increasingly popular method for automating and standardizing RAG evaluation.\n",
        "\n",
        "You will learn how to leverage the advanced capabilities of Google's Gemini LLM to act as an impartial and effective judge, providing consistent and nuanced assessments of RAG system performance."
      ],
      "metadata": {
        "id": "tret6zXCjO9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Why \"LLM as a Judge\" for RAG?**\n",
        "\n",
        "Traditional RAG evaluation often relies on strict string matching or human annotation, which can be time-consuming, prone to subjectivity, and may not fully capture the semantic quality of an LLM's output. LLMs, when appropriately prompted, can act as intelligent evaluators, assessing key aspects like:\n",
        "\n",
        "For RAG systems, this technique is particularly impactful for evaluating key aspects like:\n",
        "\n",
        "*   **Context Relevance:** Does the retrieved information truly align with the user's query?\n",
        "*   **Groundedness/Faithfulness:** Is the generated response accurately derived from the retrieved context, minimizing hallucinations?\n",
        "*   **Answer Coherence and Fluency:** Beyond factual correctness, Is the output well-structured, easy to understand, and natural-sounding?\n",
        "*   **Completeness:** Does the answer address all aspects of the user's query based on the provided context?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vknN675cjq9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What You Will Learn:**\n",
        "\n",
        "\n",
        "*   **Understanding \"LLM as Judge\":** Grasp the core concepts, benefits, and limitations of using LLMs for evaluation.\n",
        "*   **RAG Evaluation Metrics:** Explore specific metrics relevant to RAG systems (Context Relevance, Groundedness, Answer Relevancy) and how to evaluate them using an LLM judge.\n",
        "* Designing Effective Evaluation Prompts: Learn the art of crafting robust and unbiased prompts that guide Gemini to perform accurate assessments.\n",
        "* **Implementing LLM-based Evaluation with Gemini:** Get hands-on experience using the Gemini API to set up your own LLM judge for RAG systems.\n",
        "* **Setting up Evaluation Pipelines:** Discover how to integrate LLM-as-Judge into your RAG development workflow for continuous evaluation and improvement.\n",
        "* **Analyzing and Interpreting Judge Results:** Understand how to interpret scores and feedback from your Gemini judge to identify areas for RAG system optimization.\n",
        "* **Best Practices for Reliable Evaluation:** Gain insights into strategies for minimizing bias, ensuring consistency, and validating your LLM judge's performance."
      ],
      "metadata": {
        "id": "fhRwb4XJkTYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Implementing with Gemini Models**\n",
        "\n",
        "Gemini's powerful understanding and generation capabilities make it an excellent choice for building LLM-as-a-Judge systems for RAG evaluation. Here's how you can leverage them:\n",
        "\n",
        "* **Define Your Metrics & Rubric:** Clearly outline what you want to evaluate `(e.g., context precision, answer accuracy, absence of hallucination).` For each metric, create a detailed rubric that the Gemini model will use to score the RAG output.\n",
        "\n",
        "* **Craft Effective Prompts:** This is key. Design prompts that instruct Gemini to act as a judge, providing it with the query, the retrieved context, and the RAG-generated answer. The prompt should clearly state the evaluation criteria and the desired output format `(e.g., a numerical score, a binary \"pass/fail,\" or a qualitative explanation)`.\n",
        "\n",
        "* **Utilize Gemini API:** Integrate with the Gemini API to send your RAG outputs and evaluation prompts. Gemini's various models (like Gemini 1.5 Pro for complex reasoning or Gemini 1.5 Flash for faster evaluations) can be chosen based on your specific needs and budget.\n",
        "\n",
        "* **Automate and Iterate:** Set up an automated pipeline to run your RAG outputs through the Gemini-powered judge. Collect the evaluation scores and feedback, which can then inform your RAG system's improvement."
      ],
      "metadata": {
        "id": "8EsJIlikmcwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USE CASE: MEDICAL RESEARCH**\n",
        "\n",
        "This notebook showcases a practical application of Retrieval-Augmented Generation (RAG) within the specialized domain of medical research, specifically using research papers on polio as a knowledge base.\n",
        "\n",
        "The core of the RAG system lies in its ability to first retrieve relevant information from these documents and then use that information to generate a comprehensive answer to a user's query. This process ensures that the generated answers are not only accurate but also grounded in the provided context, effectively minimizing the risk of a hallucinated response.\n",
        "\n",
        "A key focus of this notebook is the **evaluation of the RAG system's output**. To this end, it introduces the concept of an **\"LLM as a Judge.\"** This innovative approach uses a separate Large Language Model to act as an impartial evaluator of the RAG system's generated answers.\n",
        "\n",
        "The \"judge\" LLM is tasked with assessing the faithfulness and relevance of the answers by comparing them against the source documents. This evaluation process is crucial for ensuring the reliability and trustworthiness of the RAG system, providing a robust mechanism for quality control and continuous improvement."
      ],
      "metadata": {
        "id": "GTXvGbWdnrLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### INSTALL"
      ],
      "metadata": {
        "id": "ukuE5IQm3idJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install requests beautifulsoup4 pypdf langchain -q -U\n",
        "%pip install google-cloud-aiplatform langchain-google-vertexai faiss-cpu langchain-community -q -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDJSL2Se3h25",
        "outputId": "42c0fbf2-65c8-4407-a7e9-1f4372631685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1: Downloading and Processing Papers with Python**\n",
        "\n",
        "To use the information within these papers, we first need to get their content into our Python environment. Since these papers are available as web pages or PDFs, we will write a script to:\n",
        "\n",
        "\n",
        "* **Fetch the content:** We'll use the requests library to download the HTML of the web pages. For the PDF, we'll use a library designed to extract text from PDF files.\n",
        "\n",
        "* **Parse the text:** Raw HTML contains a lot of code we don't need. We'll use BeautifulSoup to parse the HTML and extract only the meaningful text. For PDFs, pypdf will help us extract text directly.\n",
        "\n",
        "* **Chunk the text:** Large language models have a limited context window (the amount of text they can consider at once). A single research paper is far too long. To handle this, we break the text into smaller, overlapping \"***chunks.***\" This ensures that the model receives manageable pieces of information and that semantic meaning isn't lost at the boundaries of chunks.\n",
        "We use the `RecursiveCharacterTextSplitter` from langchain for this, a standard tool for this task.\n",
        "\n",
        "This entire process prepares the raw data for the next crucial step: creating vector embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "lzZhzc-TrEKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pypdf import PdfReader\n",
        "\n",
        "\n",
        "import sys\n",
        "from google.colab import auth\n",
        "import vertexai\n",
        "\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "7ToclvX0sCff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Define PDF URLs and a directory for text files --#\n",
        "pdf_sources = [\n",
        "    {\"name\": \"cdc_update_2024\", \"url\": \"https://www.cdc.gov/mmwr/volumes/73/wr/pdfs/mm7341a1-H.pdf\"},\n",
        "    # Corrected URL for the GPEI strategy\n",
        "    {\"name\": \"Polio_endemic_disease_pakistan\", \"url\": \"https://ecommons.aku.edu/cgi/viewcontent.cgi?article=1297&context=pakistan_fhs_son\"},\n",
        "    # This WHO link is correct but subject to rate limiting\n",
        "    {\"name\": \"polio_eradication_strategy\", \"url\": \"https://polioeradication.org/wp-content/uploads/2022/06/Polio-Eradication-Strategy-2022-2026-Delivering-on-a-Promise.pdf\"},\n",
        "    # Corrected URL for the UKHSA guide\n",
        "    {\"name\": \"who_poilio_vaccine\", \"url\": \"https://cdn.who.int/media/docs/default-source/immunization/position_paper_documents/polio/who-pp-polio-mar2016-references.pdf?sfvrsn=f4e72554_2\"}\n",
        "]\n",
        "\n",
        "# Create a directory to store the processed text\n",
        "output_dir = \"polio_papers\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n"
      ],
      "metadata": {
        "id": "dpGXdT6GuIRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Function to download and extract text from a PDF --#\n",
        "def download_and_extract_pdf_text(pdf_info):\n",
        "    \"\"\"Downloads a PDF from a URL and extracts its text content.\"\"\"\n",
        "    pdf_filename = f\"{pdf_info['name']}.pdf\"\n",
        "    text_filename = os.path.join(output_dir, f\"{pdf_info['name']}.txt\")\n",
        "\n",
        "    try:\n",
        "        # Download the PDF\n",
        "        response = requests.get(pdf_info['url'], stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(pdf_filename, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Successfully downloaded {pdf_filename}\")\n",
        "\n",
        "        # Extract text from the downloaded PDF\n",
        "        reader = PdfReader(pdf_filename)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "\n",
        "        # Save the extracted text and return it\n",
        "        with open(text_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "        print(f\"Successfully extracted and saved text to {text_filename}\")\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {pdf_filename}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_filename}: {e}\")\n",
        "    return \"\" # Return empty string on failure\n",
        "\n",
        "#--  Execute the download and extraction for all PDFs --#\n",
        "all_texts = []\n",
        "for pdf in pdf_sources:\n",
        "    extracted_text = download_and_extract_pdf_text(pdf)\n",
        "    if extracted_text:\n",
        "        all_texts.append(extracted_text)\n",
        "\n",
        "#--  Combine and chunk all extracted text --#\n",
        "full_text = \"\\n\\n--- NEW DOCUMENT ---\\n\\n\".join(all_texts)\n",
        "print(f\"\\nTotal length of combined text: {len(full_text)} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXOYOzNEube7",
        "outputId": "6749fb7b-010d-4d56-ea32-5ce9986a09ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded cdc_update_2024.pdf\n",
            "Successfully extracted and saved text to polio_papers/cdc_update_2024.txt\n",
            "Successfully downloaded Polio_endemic_disease_pakistan.pdf\n",
            "Successfully extracted and saved text to polio_papers/Polio_endemic_disease_pakistan.txt\n",
            "Successfully downloaded polio_eradication_strategy.pdf\n",
            "Successfully extracted and saved text to polio_papers/polio_eradication_strategy.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded who_poilio_vaccine.pdf\n",
            "Successfully extracted and saved text to polio_papers/who_poilio_vaccine.txt\n",
            "\n",
            "Total length of combined text: 478443 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2: Storing Information in a Vector Database**\n",
        "\n",
        "A vector database allows us to perform semantic search. Instead of just searching for keywords, we can search for concepts and meanings. Here's how it works:\n",
        "\n",
        "* **Embedding Model:** We use a model from Vertex AI to convert our text chunks into numerical representations called vectors or embeddings. Each vector is a list of numbers that captures the semantic meaning of the text. Chunks with similar meanings will have vectors that are \"close\" to each other in mathematical space.\n",
        "\n",
        "* **Vector Store:** We need a place to store these vectors and a way to search through them efficiently. FAISS is a lightweight and highly efficient library for this purpose. It's perfect for a Colab environment as it runs in memory and doesn't require a separate database server.\n",
        "\n",
        "* **Storing:** The script will take each text chunk, pass it to the Vertex AI embedding model to get a vector, and then store that vector (along with the original text chunk) in our FAISS index.\n",
        "\n",
        "\n",
        "This setup is the core of our RAG system. It allows us to take a user's question, find the most relevant chunks of information from our research papers, and use them to generate a factual, context-aware answer."
      ],
      "metadata": {
        "id": "d_ET9iutuP0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk the text\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,  # The size of each chunk in characters\n",
        "    chunk_overlap=200 # Number of characters to overlap between chunks\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "print(f\"\\nTotal number of text chunks: {len(chunks)}\")\n",
        "print(\"Sample chunk:\")\n",
        "print(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3TLO1Jso5D",
        "outputId": "9053ff53-ea98-4bdc-f6f5-032e10c24b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of text chunks: 395\n",
            "Sample chunk:\n",
            "Morbidity and Mortality Weekly Report\n",
            "U.S. Centers for Disease Control and Prevention\n",
            "Weekly / Vol. 73 / No. 41 O ctober 17, 2024\n",
            "INSIDE\n",
            "917 T obacco Product Use Among Middle and High \n",
            "School Students — National Youth Tobacco Survey, \n",
            "United States, 2024\n",
            "925 C overage with Selected Vaccines and Exemption \n",
            "Rates Among Children in Kindergarten — United \n",
            "States, 2023–24 School Year\n",
            "933 Not es from the Field: Enhanced Surveillance for \n",
            "Raccoon Rabies Virus Variant and Vaccination of \n",
            "Wildlife for Management — Omaha, Nebraska, \n",
            "October 2023–July 2024 \n",
            "936 QuickStats\n",
            "Continuing Education examination available at  \n",
            "https://www.cdc.gov/mmwr/mmwr_continuingEducation.html\n",
            "Update on Vaccine-Derived Poliovirus Outbreaks —  \n",
            "Worldwide, January 2023–June 2024\n",
            "Apophia Namageyo-Funa, PhD1; Sharon A. Greene, PhD1; Elizabeth Henderson2; Mohamed A. T raoré3; Shahzad Shaukat, PhD3; John Paul Bigouette, PhD1; \n",
            "Jaume Jorba, PhD2; Eric Wiesen, DrPH1; Omotayo Bolu, PhD1; Ousmane M. Diop, PhD3; Cara C. Burns, PhD2; Steven G.F . Wassilak, MD1\n",
            "Abstract\n",
            "Circulating vaccine-derived polioviruses (cVDPVs) can \n",
            "emerge and lead to outbreaks of paralytic polio as well as \n",
            "asymptomatic transmission in communities with a high percent-\n",
            "age of undervaccinated children. Using data from the World \n",
            "Health Organization Polio Information System and Global \n",
            "Polio Laboratory Network, this report describes global polio \n",
            "outbreaks due to cVDPVs during January 2023–June 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### SET UP VERTEX AI PROJECT"
      ],
      "metadata": {
        "id": "wpH_9qrE32zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate user\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "XNlbrcsEssTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate and initialize Vertex AI\n",
        "\n",
        "# Define your Google Cloud project\n",
        "PROJECT_ID = \"gen-lang-client-0043347732\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "Qj86yI5yswGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Set up the embedding model and FAISS vector store\n",
        "# Initialize the embedding model\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "\n",
        "# Create the vector store from our text chunks\n",
        "# This will take a moment as it processes each chunk and gets its embedding\n",
        "\n",
        "print(\"Creating vector store... This may take a few minutes.\")\n",
        "# vector_store = FAISS.from_texts(chunks, embeddings)\n",
        "vector_store = FAISS.from_texts([chunks[0]], embeddings)\n",
        "\n",
        "# Loop through the rest of the chunks, adding them one by one\n",
        "for i, chunk in enumerate(chunks[1:]):\n",
        "    # Add a small delay (e.g., 1 second) to stay under the quota\n",
        "    time.sleep(1)\n",
        "    vector_store.add_texts([chunk])\n",
        "    # Optional: print progress so you know it's working\n",
        "    print(f\"Processed chunk {i+2}/{len(chunks)}\")\n",
        "\n",
        "print(\"Vector store created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "mTqu34K4s92z",
        "outputId": "281fa392-f4d7-4e64-93b4-c1e8a53c5c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vector store... This may take a few minutes.\n",
            "Processed chunk 2/395\n",
            "Processed chunk 3/395\n",
            "Processed chunk 4/395\n",
            "Processed chunk 5/395\n",
            "Processed chunk 6/395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         )\n\u001b[0;32m-> 1192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:192.178.155.95:443 {grpc_message:\"Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\", grpc_status:8}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3890645313.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Add a small delay (e.g., 1 second) to stay under the quota\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Optional: print progress so you know it's working\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processed chunk {i+2}/{len(chunks)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36madd_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m    339\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m_embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/embeddings.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, batch_size, embeddings_task_type)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_task_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     def embed_query(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, texts, batch_size, embeddings_task_type, dimensions)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/embeddings.py\u001b[0m in \u001b[0;36m_get_embeddings_with_retry\u001b[0;34m(self, texts, embeddings_type, dimensions)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoogleEmbeddingModelType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTIMODAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_multimodal_embeddings_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             return self._get_text_embeddings_with_retry(\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dimensionality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/embeddings.py\u001b[0m in \u001b[0;36m_get_text_embeddings_with_retry\u001b[0;34m(self, texts, embeddings_type, output_dimensionality)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_dimensionality\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_embeddings_with_retry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/language_models/_language_models.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, texts, auto_truncate, output_dimensionality)\u001b[0m\n\u001b[1;32m   2190\u001b[0m         )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         prediction_response = self._endpoint.predict(\n\u001b[0m\u001b[1;32m   2193\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdedicated_endpoint_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m             prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   2451\u001b[0m                 \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chunking & Retrieval: Sample Query"
      ],
      "metadata": {
        "id": "VT7EKiy43_GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the vector store with a sample query\n",
        "# Let's see what information it retrieves for a sample question\n",
        "sample_query = \"What are the main challenges in polio eradication?\"\n",
        "retrieved_docs = vector_store.similarity_search(sample_query, k=2) # Get the top 2 most relevant chunks\n",
        "\n",
        "print(f\"\\n--- Sample Retrieval for query: '{sample_query}' ---\")\n",
        "for i, doc in enumerate(retrieved_docs):\n",
        "    print(f\"\\n--- Relevant Chunk {i+1} ---\")\n",
        "    print(doc.page_content)\n",
        "    print(\"--------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgvlCw2Os9q2",
        "outputId": "4cb6ad12-285d-4b44-ae6e-8edc04163930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying vertexai.language_models._language_models._TextEmbeddingModel.get_embeddings in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Retrieval for query: 'What are the main challenges in polio eradication?' ---\n",
            "\n",
            "--- Relevant Chunk 1 ---\n",
            "immunity by overcoming barriers to reaching children.\n",
            "Introduction\n",
            "Live, attenuated oral poliovirus vaccine (OPV) induces \n",
            "long-term protection against paralytic disease, and limits virus \n",
            "shedding in vaccinated persons with infection (1). Circulating \n",
            "vaccine-derived poliovirus (cVDPVs)* outbreaks occur when \n",
            "OPV-related strains undergo prolonged circulation in com -\n",
            "munities with very low immunity against polioviruses, and the \n",
            "genetically reverted virus has regained neurovirulence (vaccine-\n",
            "derived poliovirus [VDPV] emergence) (2,3). After declaration \n",
            "of wild poliovirus type 2 eradication in 2015, and in an effort \n",
            "to lower the risk for cVDPV type 2 (cVDPV2) outbreaks, \n",
            "immunization programs in countries using OPV switched \n",
            "from using trivalent OPV (tOPV) (containing types 1, 2, and \n",
            "3 Sabin strains) in routine and supplementary immunization \n",
            "activities (SIAs) to bivalent OPV (bOPV) (containing types 1 \n",
            "* B y genomic sequence analysis of the region encoding capsid viral protein 1, a \n",
            "poliovirus with >1% divergence from the parent Sabin strain for serotypes 1 \n",
            "and 3, or >0.6% for serotype 2, is classified as a vaccine-derived poliovirus \n",
            "(VDPV). Evidence of circulation (i.e., a cVDPV outbreak) occurs when two \n",
            "or more independent detections of genetically linked VDPVs are identified \n",
            "through acute flaccid paralysis (AFP) surveillance, environmental surveillance \n",
            "(ES), or from healthy community members.\n",
            "Morbidity and Mortality Weekly Report\n",
            "910\n",
            "--------------------\n",
            "\n",
            "--- Relevant Chunk 2 ---\n",
            "Health Organization Polio Information System and Global \n",
            "Polio Laboratory Network, this report describes global polio \n",
            "outbreaks due to cVDPVs during January 2023–June 2024 \n",
            "and updates previous reports. During the reporting period, \n",
            "74 cVDPV outbreaks were detected in 39 countries or areas \n",
            "(countries), predominantly in Africa. Among these 74 cVDPV \n",
            "outbreaks, 47 (64%) were new outbreaks, detected in 30 (77%) \n",
            "of the 39 countries. Three countries reported cVDPV type 1 \n",
            "(cVDPV1) outbreaks and 38 countries reported cVDPV type \n",
            "2 (cVDPV2) outbreaks; two of these countries reported cocir-\n",
            "culating cVDPV1 and cVDPV2. In the 38 countries with \n",
            "cVDPV2 transmission, 70 distinct outbreaks were reported. \n",
            "In 15 countries, cVDPV transmission has lasted >1 year into \n",
            "2024. In Nigeria and Somalia, both countries with security-\n",
            "compromised areas, persistent cVDPV2 transmission has spread \n",
            "to neighboring countries. Delayed implementation of outbreak \n",
            "response campaigns and low-quality campaigns have resulted in \n",
            "further international spread. Countries can control cVDPV out-\n",
            "breaks with timely allocation of resources to implement prompt, \n",
            "high-quality responses after outbreak confirmation. Stopping all \n",
            "cVDPV transmission requires effectively increasing population \n",
            "immunity by overcoming barriers to reaching children.\n",
            "Introduction\n",
            "Live, attenuated oral poliovirus vaccine (OPV) induces \n",
            "long-term protection against paralytic disease, and limits virus\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4: Generating Questions for the LLM**\n"
      ],
      "metadata": {
        "id": "_owpzmnYvNfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the content of the these papers, here are 6 insightful questions that require the LLM to synthesize information from multiple sources.\n",
        "\n",
        "\n",
        "* **Q1:** Based on the GPEI's eradication strategy and the challenges of polio\n",
        "as an endemic disease in Pakistan, what specific strategic objectives are most crucial for finally stopping transmission in the country?\n",
        "\n",
        "* **Q2:** How do the WHO's recommendations on polio vaccines align with the CDC's latest update on vaccine-derived poliovirus (cVDPV) outbreaks?\n",
        "\n",
        "* **Q3:** According to the GPEI strategy and the CDC update, what are the primary risks associated with cVDPV, and how does this challenge the goal of \"delivering on a promise\" of polio eradication?\n",
        "\n",
        "* **Q4:** Synthesizing information from the WHO vaccine document and the paper on polio in Pakistan, what are the key logistical and social challenges to achieving high vaccination coverage in endemic regions?\n",
        "\n",
        "* **Q5:** What is the global strategy for responding to a poliovirus outbreak, and how might that strategy be specifically adapted for an endemic setting like Pakistan, considering the information from all four documents?\n",
        "\n",
        "* **Q6:** According to the provided documents, what are the primary reasons for the persistence of circulating vaccine-derived poliovirus (cVDPV) outbreaks in 2023-2024, and which type is most prevalent?"
      ],
      "metadata": {
        "id": "mDc7BZ0ZySwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 5: Answering Queries with a RAG System**\n",
        "\n",
        "This is where everything comes together. We will now build the complete RAG pipeline to answer our generated questions.\n",
        "\n",
        "* **Retriever:** The vector store we built (FAISS) acts as our retriever. When a user asks a question, the retriever's job is to quickly find and \"retrieve\" the most relevant text chunks from our source documents.\n",
        "\n",
        "* **Prompt Template:** We don't just send the user's question to the LLM. We create a structured prompt. This prompt instructs the LLM on how to behave (e.g., \"be a helpful assistant\"), provides the retrieved text chunks as context, and then presents the user's question. This guides the model to base its answer only on the information we've provided.\n",
        "\n",
        "* **LLM:** We use a powerful Gemini model from Vertex AI as the \"brain\" of our operation. It will receive the formatted prompt (with context) and generate a coherent, human-like answer.\n",
        "\n",
        "* **Chain**: We use langchain to tie these components together into a RetrievalQA chain. This chain automates the entire process: a question goes in, and a fully formed, context-aware answer comes out.\n",
        "\n",
        "This RAG approach is far superior to simply asking the LLM a question directly because it grounds the model's response in our specific source material, dramatically reducing the risk of hallucinations (made-up information) and ensuring the answers are factual and relevant to our documents.\n",
        "\n"
      ],
      "metadata": {
        "id": "wJiN91QAzfVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the LLM and the QA Chain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initialize the Gemini LLM\n",
        "llm = VertexAI(model_name=\"gemini-2.0-flash-001\", temperature=0.1)"
      ],
      "metadata": {
        "id": "dIFvcdFi91e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Prompt Template: Response Generation"
      ],
      "metadata": {
        "id": "3icYxytp2PV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant specialized in summarizing information from medical research papers.\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer from the context, just say that you don't know, don't try to make up an answer.\n",
        "Be concise and provide the answer based only on the provided text.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "YfogGfbZ93tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the RetrievalQA Chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "1vjxcBih9-ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Response Q1"
      ],
      "metadata": {
        "id": "fBEkE0C90_u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask one of our generated questions\n",
        "question_to_ask = \"\"\"Based on the GPEI's eradication strategy and the challenges of polio as an endemic disease in Pakistan,\n",
        "                      what specific strategic objectives are most crucial for finally stopping transmission in the country?\"\"\"\n",
        "\n",
        "print(f\"Asking question: {question_to_ask}\")\n",
        "result = qa_chain({\"query\": question_to_ask})\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n--- Generated Answer ---\")\n",
        "print(result[\"result\"])\n",
        "\n",
        "print(\"\\n--- Source Documents Used ---\")\n",
        "for doc in result[\"source_documents\"]:\n",
        "    print(f\"\\n- Source: {doc.page_content[:200]}...\") # Print snippet of the source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwk0MvajuB6l",
        "outputId": "99b613fd-3858-4200-b66b-c4abdb941cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking question: Based on the GPEI's eradication strategy and the challenges of polio as an endemic disease in Pakistan, \n",
            "                      what specific strategic objectives are most crucial for finally stopping transmission in the country?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1043197360.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": question_to_ask})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generated Answer ---\n",
            "I am sorry, but the text does not contain information about the GPEI's eradication strategy, polio as an endemic disease in Pakistan or the strategic objectives for stopping transmission in the country.\n",
            "\n",
            "\n",
            "--- Source Documents Used ---\n",
            "\n",
            "- Source: immunity by overcoming barriers to reaching children.\n",
            "Introduction\n",
            "Live, attenuated oral poliovirus vaccine (OPV) induces \n",
            "long-term protection against paralytic disease, and limits virus \n",
            "shedding in...\n",
            "\n",
            "- Source: Health Organization Polio Information System and Global \n",
            "Polio Laboratory Network, this report describes global polio \n",
            "outbreaks due to cVDPVs during January 2023–June 2024 \n",
            "and updates previous repor...\n",
            "\n",
            "- Source: mended vaccine for cVDPV2 outbreak response (5). However, \n",
            "nOPV2 supply has been periodically restricted because of \n",
            "manufacturing delays, including during a period in early 2024. \n",
            "Despite the goal of...\n",
            "\n",
            "- Source: Morbidity and Mortality Weekly Report\n",
            "U.S. Centers for Disease Control and Prevention\n",
            "Weekly / Vol. 73 / No. 41 O ctober 17, 2024\n",
            "INSIDE\n",
            "917 T obacco Product Use Among Middle and High \n",
            "School Students...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Response Q6"
      ],
      "metadata": {
        "id": "KP4E5j-61Lka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--  Ask one of our generated questions --#\n",
        "question_to_ask6 = \"According to the provided documents, what are the primary reasons for the persistence of circulating vaccine-derived poliovirus (cVDPV) outbreaks in 2023-2024, and which type is most prevalent?\"\n",
        "\n",
        "print(f\"Asking question: {question_to_ask6}\")\n",
        "result6 = qa_chain({\"query\": question_to_ask6})\n",
        "\n",
        "#--  Print the results --#\n",
        "print(\"\\n--- Generated Answer ---\")\n",
        "print(result6[\"result\"])\n",
        "\n",
        "print(\"\\n--- Source Documents Used ---\")\n",
        "for doc in result6[\"source_documents\"]:\n",
        "    print(f\"\\n- Source: {doc.page_content[:200]}...\") # Print snippet of the source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Q1FEHB1ODO",
        "outputId": "69a91349-7f0a-4d43-d1d1-3716f519431c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking question: According to the provided documents, what are the primary reasons for the persistence of circulating vaccine-derived poliovirus (cVDPV) outbreaks in 2023-2024, and which type is most prevalent?\n",
            "\n",
            "--- Generated Answer ---\n",
            "The persistence of cVDPV outbreaks is primarily due to delayed implementation of outbreak response campaigns, low-quality campaigns, and barriers to reaching children to increase population immunity. cVDPV type 2 (cVDPV2) outbreaks are the most prevalent.\n",
            "\n",
            "\n",
            "--- Source Documents Used ---\n",
            "\n",
            "- Source: Health Organization Polio Information System and Global \n",
            "Polio Laboratory Network, this report describes global polio \n",
            "outbreaks due to cVDPVs during January 2023–June 2024 \n",
            "and updates previous repor...\n",
            "\n",
            "- Source: Morbidity and Mortality Weekly Report\n",
            "U.S. Centers for Disease Control and Prevention\n",
            "Weekly / Vol. 73 / No. 41 O ctober 17, 2024\n",
            "INSIDE\n",
            "917 T obacco Product Use Among Middle and High \n",
            "School Students...\n",
            "\n",
            "- Source: mended vaccine for cVDPV2 outbreak response (5). However, \n",
            "nOPV2 supply has been periodically restricted because of \n",
            "manufacturing delays, including during a period in early 2024. \n",
            "Despite the goal of...\n",
            "\n",
            "- Source: immunity by overcoming barriers to reaching children.\n",
            "Introduction\n",
            "Live, attenuated oral poliovirus vaccine (OPV) induces \n",
            "long-term protection against paralytic disease, and limits virus \n",
            "shedding in...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 6: Using an LLM as a Judge**\n",
        "\n",
        "How do we know if our RAG system is providing good answers? We can evaluate them manually, but this is time-consuming. An advanced and powerful technique is to use another **LLM as an impartial \"judge.\"**\n",
        "\n",
        "* **The Judge's Task:** We give the judge LLM a very specific set of instructions. Its job is not to answer the original question, but to evaluate the answer generated by our RAG system.\n",
        "\n",
        "* **Evaluation Criteria:** We define clear criteria for the judge. In this script, we ask it to assess two key aspects:\n",
        "\n",
        " * **Faithfulness:** Is the generated answer fully supported by the provided source documents? It should not contain information that isn't in the context.\n",
        "\n",
        " * **Relevance:** Does the answer directly address the user's question?\n",
        "\n",
        "* **Structured Output:** We instruct the judge to provide its reasoning and a final verdict (\"SUPPORTED\" or \"NOT SUPPORTED\") in a structured format. This makes the evaluation easy to interpret.\n",
        "\n",
        "Using an LLM Judge automates the evaluation process, allowing us to quickly assess the quality of our RAG system's responses. It's a key part of building robust and reliable AI systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "DXFcEpbWDsA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Judge LLM and Prompt Template\n",
        "judge_llm = VertexAI(model_name=\"gemini-2.5-pro\", temperature=0.0)"
      ],
      "metadata": {
        "id": "g1OTDrrOFdlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Prompt Template: LLM Judge"
      ],
      "metadata": {
        "id": "04_wHEph2oQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_criteria_judge_prompt = \"\"\"\n",
        "You are an expert, impartial evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
        "Your task is to evaluate a generated answer based on a given question and the source context documents.\n",
        "\n",
        "Please evaluate the provided response based on the following four criteria. For each criterion, provide a score from 1 to 5 (where 1 is worst and 5 is best) and a brief justification for your score.\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "\n",
        "1.  **Context Relevance (Score 1-5):**\n",
        "    - Does the retrieved context truly align with the user's query?\n",
        "    - Are the source documents pertinent to answering the question?\n",
        "    - **Justification:**\n",
        "\n",
        "2.  **Groundedness/Faithfulness (Score 1-5):**\n",
        "    - Is the generated response accurately derived from the retrieved context?\n",
        "    - Does it avoid making up information (hallucinations)?\n",
        "    - **Justification:**\n",
        "\n",
        "3.  **Answer Coherence and Fluency (Score 1-5):**\n",
        "    - Is the output well-structured, grammatically correct, and easy to understand?\n",
        "    - Does it sound natural?\n",
        "    - **Justification:**\n",
        "\n",
        "4.  **Completeness (Score 1-5):**\n",
        "    - Does the answer address all aspects of the user's query based on the provided context?\n",
        "    - **Justification:**\n",
        "\n",
        "**Input:**\n",
        "\n",
        "---\n",
        "**Original Question:**\n",
        "{question}\n",
        "\n",
        "---\n",
        "**Source Documents (Context):**\n",
        "{context}\n",
        "\n",
        "---\n",
        "**Generated Answer:**\n",
        "{answer}\n",
        "---\n",
        "\n",
        "**Evaluation Output:**\n",
        "\n",
        "Please provide your evaluation in the format specified above.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GWt34HnFqhQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluation: Q1"
      ],
      "metadata": {
        "id": "Qu7s3N2K1k-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the inputs for the judge\n",
        "# We will use the results from the previous step\n",
        "question = result[\"query\"]\n",
        "context_docs = \"\\n\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
        "generated_answer = result[\"result\"]\n",
        "\n",
        "# Format the input for the judge\n",
        "judge_input = multi_criteria_judge_prompt.format(\n",
        "    question=question,\n",
        "    context=context_docs,\n",
        "    answer=generated_answer\n",
        ")"
      ],
      "metadata": {
        "id": "dbVfEmYX_B7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the evaluation from the judge\n",
        "print(\"\\n--- ⚖️ Submitting to LLM Judge for Evaluation ⚖️ ---\")\n",
        "evaluation = judge_llm(judge_input)\n",
        "\n",
        "# Print the judge's verdict\n",
        "print(\"\\n--- Judge's Evaluation ---\")\n",
        "print(evaluation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1STxvZJa-1nT",
        "outputId": "ef3457be-2cc7-4d66-ab5c-659158b097ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ⚖️ Submitting to LLM Judge for Evaluation ⚖️ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3693659235.py:3: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  evaluation = judge_llm(judge_input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Judge's Evaluation ---\n",
            "**Evaluation Output:**\n",
            "\n",
            "**1. Context Relevance (Score 1-5):**\n",
            "- **Score:** 1\n",
            "- **Justification:** The retrieved context is a general report on worldwide vaccine-derived poliovirus (cVDPV) outbreaks, with a focus on Africa. It does not contain any specific information about the GPEI's strategy, the situation in Pakistan, or polio as an endemic disease in that country. The source documents are entirely irrelevant to the user's specific query.\n",
            "\n",
            "**2. Groundedness/Faithfulness (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The generated answer is perfectly faithful to the provided context. It correctly identifies that the source documents do not contain the information required to answer the question about Pakistan or the GPEI's strategy. It avoids hallucination and accurately reports on the absence of relevant data.\n",
            "\n",
            "**3. Answer Coherence and Fluency (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The answer is a single, well-formed sentence that is grammatically correct, clear, and easy to understand. It is a fluent and appropriate response for a system that cannot find the requested information in its sources.\n",
            "\n",
            "**4. Completeness (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** Based on the provided context, this is the most complete answer possible. Since the source documents lack any of the requested information, the answer correctly and completely addresses the user's query by stating that it cannot be answered from the given text. Answering in any other way would have been unfaithful to the source.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluation: Q6"
      ],
      "metadata": {
        "id": "Om88e9571qup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the inputs for the judge\n",
        "# We will use the results from the previous step\n",
        "question = result6[\"query\"]\n",
        "context_docs = \"\\n\\n\".join([doc.page_content for doc in result6[\"source_documents\"]])\n",
        "generated_answer = result6[\"result\"]\n",
        "\n",
        "# Format the input for the judge\n",
        "judge_input = multi_criteria_judge_prompt.format(\n",
        "    question=question,\n",
        "    context=context_docs,\n",
        "    answer=generated_answer\n",
        ")"
      ],
      "metadata": {
        "id": "zfo0UipL1ysT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the evaluation from the judge\n",
        "print(\"\\n--- ⚖️ Submitting to LLM Judge for Evaluation ⚖️ ---\")\n",
        "evaluation = judge_llm(judge_input)\n",
        "\n",
        "# Print the judge's verdict\n",
        "print(\"\\n--- Judge's Evaluation ---\")\n",
        "print(evaluation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8oulefs180O",
        "outputId": "cc1aa574-6427-49dd-e21b-76a0eb597a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ⚖️ Submitting to LLM Judge for Evaluation ⚖️ ---\n",
            "\n",
            "--- Judge's Evaluation ---\n",
            "**Evaluation Output:**\n",
            "\n",
            "**1. Context Relevance (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The provided source documents are excerpts from a CDC report titled \"Update on Vaccine-Derived Poliovirus Outbreaks — Worldwide, January 2023–June 2024.\" This is perfectly aligned with the user's question about the reasons for cVDPV outbreaks during that specific time frame. The context is highly pertinent and directly contains the necessary information.\n",
            "\n",
            "**2. Groundedness/Faithfulness (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The generated answer is entirely faithful to the source documents. Each point is directly supported by the text:\n",
            "    - \"Delayed implementation of outbreak response campaigns and low-quality campaigns\" is stated verbatim in the context.\n",
            "    - \"barriers to reaching children to increase population immunity\" is a direct synthesis of the phrase \"overcoming barriers to reaching children\" to \"increase population immunity.\"\n",
            "    - The statement that cVDPV2 is most prevalent is supported by the data showing 38 countries reported cVDPV2 outbreaks versus only 3 for cVDPV1. The answer contains no hallucinations.\n",
            "\n",
            "**3. Answer Coherence and Fluency (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The answer is exceptionally well-structured, fluent, and easy to understand. It combines the answers to both parts of the question into a single, concise, and grammatically correct sentence that reads naturally.\n",
            "\n",
            "**4. Completeness (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The answer fully addresses both parts of the user's query. It clearly states the primary reasons for the persistence of the outbreaks and correctly identifies cVDPV2 as the most prevalent type, as detailed in the provided context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluation: Wrong Answer"
      ],
      "metadata": {
        "id": "IQdFPN6C2xVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the same setup as before, but with our new unsupported answer.\n",
        "\n",
        "# --- Inputs for the judge ---\n",
        "# The question and context remain the same from our previous RAG query.\n",
        "question = result[\"query\"]\n",
        "context_docs = \"\\n\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
        "\n",
        "# Here is our manually crafted unsupported answer\n",
        "unsupported_answer = \"The primary reasons for the persistence of cVDPV outbreaks are low immunization coverage in certain areas and interruptions to vaccination campaigns. The most prevalent type is cVDPV2. A new, more resilient strain, cVDPV3, also emerged in late 2024 in South America, causing significant concern.\"\n",
        "\n",
        "# --- Format the prompt for the judge ---\n",
        "judge_input = multi_criteria_judge_prompt.format(\n",
        "    question=question,\n",
        "    context=context_docs,\n",
        "    answer=unsupported_answer\n",
        ")\n",
        "\n",
        "# --- Get the evaluation ---\n",
        "print(\"\\n--- ⚖️ Submitting MODIFIED Answer to LLM Judge ⚖️ ---\")\n",
        "evaluation = judge_llm(judge_input)\n",
        "\n",
        "# --- Print the judge's verdict ---\n",
        "print(\"\\n--- Judge's Evaluation of Unsupported Answer ---\")\n",
        "print(evaluation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB73mP7cM6CQ",
        "outputId": "3ba5eb92-ad5b-4f10-9485-fbf366ef242b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ⚖️ Submitting MODIFIED Answer to LLM Judge ⚖️ ---\n",
            "\n",
            "--- Judge's Evaluation of Unsupported Answer ---\n",
            "**Evaluation Output:**\n",
            "\n",
            "**1. Context Relevance (Score 1-5):**\n",
            "- **Score:** 1\n",
            "- **Justification:** The provided context is a global update on vaccine-derived poliovirus outbreaks. The user's question is highly specific, asking about the GPEI's strategy and challenges related to polio in Pakistan. The source documents do not mention Pakistan or the GPEI's specific strategy, making them almost entirely irrelevant for answering the user's query.\n",
            "\n",
            "**2. Groundedness/Faithfulness (Score 1-5):**\n",
            "- **Score:** 1\n",
            "- **Justification:** The generated answer contains a significant hallucination. The statement, \"A new, more resilient strain, cVDPV3, also emerged in late 2024 in South America, causing significant concern,\" is completely fabricated and not supported by the source documents, which only discuss cVDPV1 and cVDPV2 up to June 2024.\n",
            "\n",
            "**3. Answer Coherence and Fluency (Score 1-5):**\n",
            "- **Score:** 5\n",
            "- **Justification:** The generated answer is well-written, grammatically correct, and easy to understand. The sentences flow logically and the language is fluent.\n",
            "\n",
            "**4. Completeness (Score 1-5):**\n",
            "- **Score:** 1\n",
            "- **Justification:** The answer completely fails to address the core components of the question. It does not mention Pakistan, the GPEI's strategy, or the \"specific strategic objectives\" required to stop transmission in that country. Instead, it provides a very high-level, generic summary of global challenges, which does not fulfill the user's request.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### END"
      ],
      "metadata": {
        "id": "eacA5Y0V274L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What We Learned**\n",
        "\n",
        "A simple \"supported\" or \"not supported\" verdict is good, but a truly robust evaluation requires a more nuanced approach. To thoroughly assess RAG system's performance, we used an LLM Judge to score the output against four distinct criteria. This gave us a much clearer picture of the system's strengths and weaknesses.\n",
        "\n",
        "* **Context Relevance:** This checks if the documents retrieved from our vector database are actually relevant to the user's question. **A low score here indicates a problem with our retriever (the vector search).**\n",
        "\n",
        "* **Groundedness/Faithfulness:** This is the core of hallucination detection. It verifies that the generated answer is strictly based on the information present in the retrieved context and does not invent facts. **A low score means the LLM is hallucinating.**\n",
        "\n",
        "* **Answer Coherence and Fluency:** This assesses the quality of the generated text itself. Is the answer well-written, grammatically correct, and easy for a human to understand? **An answer can be factual but poorly structured.**\n",
        "\n",
        "* **Completeness:** This checks if the answer addresses all parts of the user's question. For example, if the question asks for \"reasons and the most prevalent type,\" **a complete answer must address both points.**\n",
        "\n",
        "By instructing our LLM Judge to provide a score and reasoning for each criterion, we can pinpoint exactly where our RAG system excels or fails, allowing for more targeted improvements."
      ],
      "metadata": {
        "id": "obtfEY2h87M-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x5v5SJDZ9fnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}